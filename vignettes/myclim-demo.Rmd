---
title: "myClim: microclimatic data in R"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{myClim: microclimatic data in R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
This vignette describes the handling of microclimatic data in R with myClim library. 

## myClim objects
MyClim holds data in two slightly different data formats consist of Lists and S3 classes: Prep-format and Calc-format. Microclimatic data are organised in localities, loggers and sensors. 
Prep-format is designed for data preparations and cleaning,
Calc-format is for calculations with pre-processed data.   
For detailed description and schema of myClim Prep-format or Calc-format see `help("myClim")`  


## Read microclimatic data
myClim read multiple formats of data downloaded from various loggers. The myClim automatically detects certain structure of knwn logger output files, but user must specify the family of loggers (based on manufacturer) by providing `dataformat_name=` one of `r names(myClim::mc_data_formats)`.

For the analysis it is more practical to use `mc_read_data()` where can user organise loggers to the localities and provide metadata. Inputs are two tables:  

1.) table with logger files paths, dataformat name,  logger type and locality
2.) table with locality metadata e.g., coordinates, altitude, time zone information.

For fast exploration, user can read files without metadata, using functions `mc_read_files()`, `mc_read_wide()`, `mc_read_long()` myClim automatically generates localities from each data file.

Output of reading functions is myClim object in Prep-format designed for data cleaning and joining. See `help("myClim")`.

```{r eval=TRUE,warning=FALSE}
library(myClim)
## Read without metadata
# read from TOMST files
tms.f <- mc_read_files(c("data_91184101_0.csv","data_94184102_0.csv",
                         "data_94184103_0.csv"), dataformat_name="TOMST"
                       ,silent = T)
# read from HOBO files
hob.f <- mc_read_files(c("20024354_comma.csv","20024354_semicolon.txt",
                         "20024354_tab.txt"), 
                       dataformat_name="HOBO",
                       date_format = "%d.%m.%y %H:%M:%S",
                       silent = T)

# read all Tomst files from current directory
tms.d <- mc_read_files(".", dataformat_name="TOMST",recursive = F,silent = T)

# read from data.frame
meteo.table<-readRDS("airTmax_meteo.rds") # wide format data frame 
meteo<-mc_read_wide(meteo.table,sensor_id = "T_C", 
                    sensor_name = "airTmax",silent = T)

## Read with metadata
# provide two tables. Can be csv files 
tms.m <- mc_read_data(files_table = "files_table.csv",
                      localities_table ="localities_table.csv",
                      silent = T)

# can be R data.frames
files_table<-read.table("files_table.csv",sep=",",header = T)
localities_table<-read.table("localities_table.csv",sep=",",header = T)
tms.m <- mc_read_data(files_table, localities_table,silent = T)

```


## Pre-Prprocessing

* **Cleaning time series:** `mc_prep_clean()` checks the order and continuity of time-series, prints log  in console. Log is sved in myClim object and can be called ex post `mc_info_clean()`.   

```{r eval=TRUE}
tms<-mc_prep_clean(tms.m) # clean series
tms.info<-mc_info_clean(tms) # call cleaning log
```


* **Handling time zones:** `mc_prep_solar_tz()` myClim expect input data in UTC time.But sometimes, especially while handling records from large spatial scales, it is ecologically useful to use rather solar time, which respects local photo-period. Solar time is calculated from longitude of locality. When user want to set custom time zone offset e.g. UTC to local political time or also in cases the data is in local time and user wish to standardize to the UTC, than use `mc_prep_meta_locality()` 


```{r eval=TRUE}

tms<-mc_prep_solar_tz(tms) # calculate solar time

# provide user defined offset to UTC
tms.usertz<-mc_prep_meta_locality(tms,values=as.list(c(A1E05=57,
                                                       A2E32=62,
                                                       A6W79=55)),
                                  param_name = "tz_offset")
```


* **Sensor calibration:** In case user have calibration data (offsets) it is possible to correct measurements with them. Use `mc_prep_calib_load()` to upload calibration data (offsets) into myClim object. Then use `mc_prep_calib()` to apply the offset correction.


```{r eval=TRUE}
# simulate calibration data
i<-mc_info(tms)
calib_table<-data.frame(serial_number=i$serial_number,
                        sensor_id=i$sensor_id,
                        datetime=as.POSIXct("2016-11-29"),
                        cor_factor=0.398,
                        cor_slope=0)

# load calibration to myClim metadata 
tms.load<-mc_prep_calib_load(tms,calib_table)

## run calibration for selected sensors
tms<-mc_prep_calib(tms.load,sensors = c("TM_T",
                                        "TMS_T1",
                                        "TMS_T2",
                                        "TMS_T3"))
```


* **Info functions:** For data overview it useful to call `mc_info_count()` which returns the number of localities, loggers and sensors in myClim object, `mc_info()` returning data frame with handy summary per sensor, `mc_info_meta()` returning the data frame with locality metadata and `mc_info_clean()` with cleaning log. 

```{r, eval=FALSE,error=FALSE,warning=FALSE}
mc_info_count(tms)
mc_info_clean(tms)
mc_info(tms)
```

Example output table of `mc_info()`

```{r, results = "asis",echo=FALSE,error=FALSE,warning=FALSE}
library(kableExtra)
kable(head(mc_info(tms),10), "html", digits=2) %>%
  kable_styling(font_size = 9)
```


* **Cropping, filtering, and merging:** For filtering and sub-setting of myClim sensors and localities use `mc_filter()`. To merge localities or add sensors to localities use `mc_prep_merge()`. For cropping the time-series to start from certain date and last till certain date use `mc_prep_crop()`

```{r eval=TRUE}

## crop the time extent for all localities
start<-as.POSIXct("2021-01-01",tz="UTC")
end<-as.POSIXct("2021-03-31",tz="UTC")
tms<-mc_prep_crop(tms,start,end)


## simulate another myClim object and rename some localities and sensors
tms1<-tms
tms1<-mc_prep_meta_locality(tms1, list(A1E05="ABC05", A2E32="CDE32"), 
                            param_name="locality_id") # change locality ID

tms1<-mc_prep_meta_sensor(tms1, values=list(TMS_T1="TMS_Tsoil", TMS_T2="TMS_Tair2cm"),
                          localities = "A6W79", param_name="name") # change sensor names

## merge two myClim objects Prep-format
tms.m<-mc_prep_merge(list(tms,tms1))
tms.im<-mc_info(tms.m) # see info 

## Filtering 
tms.m<-mc_filter(tms.m,localities = "A6W79",reverse = T) # delete one locality.
tms.m<-mc_filter(tms.m,sensors = c("TMS_T2","TMS_T3"),reverse = F) # keep only two sensor
tms.if<-mc_info(tms.m) # see info 
```


* **Updating metadata** For update locality metadata there is`mc_prep_meta_locality()` Using this, user can e.g., rename the locality, set time offset, coordinates, altitude.... For updating sensor metadata there is `mc_prep_meta_sensor()` which can only rename the sensor and update sensor height/depth. Many sensors have pre-defined height, height is important for data joining.  

```{r eval=TRUE}
## upload metadata from data frame

# load  data frame with metadata (coordinates)
metadata<-readRDS("metadata.rds")

# upload metadata from data.frame
tms.f<-mc_prep_meta_locality(tms.f, values=metadata)

## upload metadata from named list
tms.usertz<-mc_prep_meta_locality(tms,values=as.list(c(A1E05=57,
                                                       A2E32=62,
                                                       A6W79=55)),
                                  param_name = "tz_offset")

```

Metadata table ready for `mc_prep_meta_locality()`

```{r, results = "asis",echo=FALSE,error=FALSE,warning=FALSE}
library(kableExtra)
kable(metadata, "html", digits=2) %>%
  kable_styling(font_size = 9)
```

* **Joining in time** For joining fragmented time-series stored in separate files from separate downloading visits of the localities use `mc_mc_join()`. First read separate files into myClim Prep-format and then join. myClim detcts automatically which time series to join based on locality ID, logger type and time step. myClim join automatically the time series which fits well (i) newer time-series starts at the point when older ends or (ii) older and newer time-series overlaps partly or completely with identical values. In case time_series does not fit well (conflict values in certain time step) interactive process starts and user must define which time-series to use, or provide the split date from where to use the newewr data. 


```{r,eval=FALSE}

# one locality with two downloads in time 
data<-readRDS("join_example.rds") 

joined_data <- mc_join(data, comp_sensors=c("TMS_T1", "TMS_T2"))

#> Locality: 94184102
#> Problematic interval: 2020-12-01 UTC--2020-12-31 23:45:00 UTC
#> Older logger TMS 94184102
#>      tag               start                 end
#> 1 source 2020-10-06 09:15:00 2020-12-31 23:45:00
#>                                                                 value
#> 1 D:\\Git\\microclim\\examples\\data\\join\\1deg\\data_94184102_0.csv
#> Newer logger TMS 94184102
#>      tag      start                 end                                                               value
#> 1 source 2020-12-01 2021-04-07 11:45:00 D:\\Git\\microclim\\examples\\data\\join\\1deg\\data_94184102_1.csv
#> Loggers are different. They cannot be joined automatically.
#> 
#> 1: use older logger
#> 2: use newer logger
#> 3: use always older logger
#> 4: use always newer logger
#> 5: exit
#> 
#> Write choice number or start datetime of use newer logger in format YYYY-MM-DD hh:mm.
#> CHOICE>
```

<img src="join_plot.png" width="700"/>

## Plotting
`myClim` is equipped with handy plotting tools mainly from ggplot. It is possible to plot raster plot with `mc_plot_raster()` or line time series with `mc_plot_line()`. Line time series supports max. two different physical units to be plotted (primary and secondary y axis. Plotting functions save pdf or png files on your drive. 

```{r,eval=FALSE}
load("mc_data_example_calc.rda")

## lines
# mc_plot_line(mc_data_example_calc,filename = "lines.png",
#              sensors = c("TMS_T3","TMS_TMSmoisture"),png_width = 2500)
mc_plot_line(mc_data_example_calc,filename = "lines.pdf",sensors = c("TMS_T3","TMS_TMSmoisture"))

## raster
# mc_plot_raster(mc_data_example_calc,filename = "raster.png",
#                sensors = c("TMS_T3","TM_T"),png_width = 2500,png_height = 500)
mc_plot_raster(mc_data_example_calc,filename = "raster.pdf",sensors = c("TMS_T3","TM_T"))

```

<img src="raster.png" width="700"/>
<img src="lines.png" width="700"/>

## Aggregation
With the `mc_agg()` function you can  aggregate e.g., form 15 min time-series to hours, dais, weeks months, seasons, years with several functions e.g., mean, max, percentile, sum... Aggregated myClim object is in Calc-format. The `mc_agg()` called with ***fun = NULL, period = NULL*** only converts Prep-formt to Calc-format without time step change.  
```{r,eval=TRUE,warning=F}
#with defaults only convert Prep-format  to Calc-format
tms.ag<-mc_agg(tms,fun = NULL, period = NULL) 

# aggregate to daily mean, range, coverage, and 95 percentile. 
tms.day<-mc_agg(tms, fun=c("mean","range","coverage","percentile"),
                percentiles = 95, period = "day")

# aggregate all time-series, return one value per sensor.
tms.all<-mc_agg(tms, fun=c("mean","range","coverage","percentile"),
                percentiles = 95, period = "all")
```

## Calculation
With myClim Calc-format objects it is possible to calculate new virtual sensors. E.g., volumetric water content, growing and freezing degree days, snow cover duration. 
```{r,eval=TRUE,warning=F}

# calculate volumetric water content from raw Tomst moisture
tms.calc<-mc_calc_vwc(tms.ag)

# calculate growing and freezing degree days
tms.calc<-mc_calc_gdd(tms.calc,sensor = "TMS_T3",)
tms.calc<-mc_calc_fdd(tms.calc,sensor = "TMS_T3")

#estimate snow presence from 2 cm air temperature 
tms.calc<-mc_calc_snow(tms.calc,sensor = "TMS_T2")

#summary data.frame of snow estimation
tms.snow<-mc_calc_snow_agg(tms.calc)

```


Output table of `mc_calc_snow_agg`

```{r, results = "asis",echo=FALSE,error=FALSE,warning=FALSE}
library(kableExtra)

kable(tms.snow, "html", digits=2) %>%
  kable_styling(font_size = 10)
```
## Reshaping
Microclimatic records from `myClim` objects can be converted to wide or long data frame `mc_reshape_wide()` and `mc_reshape_long()`

```{r, eval=TRUE}

## wide table of air temperature and soil moisture
tms.wide<-mc_reshape_wide(tms.calc,sensors = c("TMS_T3","vwc_moisture"))

## long table of air temperature and soil moisture
tms.long<-mc_reshape_long(tms.calc,sensors = c("TMS_T3","vwc_moisture"))

```

**Reshape wide**
```{r, results = "asis",echo=FALSE,error=FALSE,warning=FALSE}
library(kableExtra)
kable(head(tms.wide,10), "html", digits=2) %>%
  kable_styling(font_size = 9)
```


**Reshape long**
```{r, results = "asis",echo=FALSE,error=FALSE,warning=FALSE}
library(kableExtra)
kable(head(tms.long,10), "html", digits=2) %>%
  kable_styling(font_size = 9)
```
## General notes

* `myClim` package was written using R, we did not design any function in other programming language. 
* `myClim` functions always return new `myClim` object instead of updating existing.
* Some `myClim` functions works only with Prep-format, some only with Calc-formats and will complain when you mess up, but other functions can handle both. 

## To do (work in progress)

* reading iButton, Lascar... files
* more calculation functions (VPD...)


